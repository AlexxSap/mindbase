#+title: Многопоточность на С++

ссылка на [[https://en.cppreference.com/w/cpp/thread][cppreference]]

* Конкурентность и параллелизм
=Конкурентность= означает, что несколько задач выполняются одновременно, но не обязательно одновременно на физическом уровне (на разных процессорах или ядрах). Задачи могут быть переключены между собой, чтобы дать иллюзию одновременного выполнения.
=Параллелизм= означает фактическое одновременное выполнение нескольких задач на разных физических ресурсах, таких как множество процессоров или ядер в многоядерной системе. При использовании параллелизма, задачи действительно выполняются одновременно и могут значительно увеличить производительность приложения.
Основное отличие между =конкуренцией= и =параллелизмом= заключается в том, что конкуренция описывает способность системы обрабатывать множество задач одновременно, независимо от физического параллелизма.

* Процесс и поток
=Поток= — это процедура выполнения на процессоре (в рамках какого-то =процесса=) набора инструкций, программного кода. Его назначение — параллельное выполнение на процессоре двух или более различных задач. Все =потоки= в =процессе= разделяют его адресное пространство.
=Процесс= — это абстракция, которая инкапсулирует в себе все ресурсы процесса и их дескрипторы, потоки и т.д. Каждый процесс имеет как минимум один поток.

* std::execution
Единый фреймворк асинхронности и параллелизма.
В С++26 обещают развить это во что-то [[https://en.cppreference.com/w/cpp/execution][страшно большое]] . Но сейчас есть только работа этой штуки в алгоритмах на коллекциях.

Есть 4 варианта:
 + =seq= - std::execution::sequenced_policy - это default поведение. Алгоритм не должен быть параллелизован или векторизован библиотекой.
 + =par= - std::execution::parallel_policy - эта политика объявляет, что вызов алгоритма безопасен от race condition и deadlock (или как мне прикольно перевёл яндекс гпт =расовых условий и мёртвых замков=). Поэтому библиотека может параллелизовать алгоритм (но не может векторизовать).
 + =par_unseq= - std::execution::parallel_unsequenced_policy - эта политика объявляет, что вызов алгоритма можно векторизовать. Это значит, что тело функции можно запускать для нескольких значений одновременно в том же потоке.
 + =unseq= - std::execution::unsequenced_policy - эта политика объединяет гарантии политик =par= и =unseq= и должна обеспечивать наивысший уровень оптимизации.

Так вот оно указывается:
#+begin_src cpp
std::for_each(std::execution::par, std::begin(container), std::end(container), [](){...});
#+end_src

*НО* указание параллельной политики НЕ гарантирует параллельное выполнение, так как решение зависит от реализации и runtime-среды.
[[./exec_pol/main.cpp][жми сюда]]

* Потоки
** std::tread
Основной класс для создания новых потоков в C++ – это =std::thread=.
+ Объект класса представляет собой один поток выполнения.
+ Новый поток начинает выполнение сразу же после построения объекта =std::thread=.
+ Возвращаемое значение функции потока, а если в ней будет брошено исключение, которое не будет обработано в этом же потоке, то вызовется =std::terminate=.
+ Передать возвращаемое значение или исключение из нового потока наружу можно через =std::promise= или через глобальные переменные.
+ Объекты =std::thread= также могут быть не связаны ни с каким потоком (после =default construction=, =move from=, =detach= или =join=), и поток выполнения может быть не связан ни с каким объектом =std::thread= (после =detach=).
+ Никакие два объекта =std::thread= не могут представлять один и тот же поток выполнения; =std::thread= нельзя копировать, но можно перемещать.

 #+begin_src cpp
void do_some_work();
std::thread my_thread(do_some_work);
 #+end_src

После запуска потока, нужно принять однозначное решение, ждать ли его завершения (=join=) или пустить его в фоне (=detach=).
Дождаться завершения потока можно, вызвав =join()= для связанного экземпляра =std::thread=. Вызов =join()= приводит к очистке объекта =std::thread=, поэтому объект =std::thread= больше не связан с завершенным потоком.
Вызов метода =detach()= для объекта =std::thread= позволяет потоку выполняться в фоновом режиме, непосредственное взаимодействие с ним не требуется. Возможность дождаться завершения этого потока исчезает: если поток отсоединяется, получить ссылающийся на него объект =std::thread= невозможно, поэтому такой поток больше нельзя присоединить.

** std::jthread
В С++20 появился новый класс для создания потоков и управления ими =std::jthread=.
Он имеет то же поведение, что и =std::thread=, за исключением того, что =jthread= автоматически join'ится при уничтожении и предлагает интерфейс для остановки потока.

** threads managing
Стандартная библиотека предоставляет несколько методов для управления текущим потоком. Все они находятся в пространстве имён =std::this_thread=:
+ =std::this_thread::yield()= подсказывает планировщику потоков перепланировать выполнение, приостановив текущий поток и отдав преимущество другим потокам. Точное поведение этой функции зависит от реализации, в частности от механики используемого планировщика ОС и состояния системы.
+ =std::this_thread::get_id()= возвращает id потока..
+ =std::this_thread::sleep_for(sleep_duration)= блокирует выполнение текущего потока на время =sleep_duration=.
+ =std::this_thread::sleep_until(sleep_time)= блокирует выполнение текущего потока до наступления момента времени =sleep_time=.

** std::async
=std::async= — это высокоуровневый способ запуска асинхронных задач. Он возвращает объект =std::future=, который можно использовать для получения результата задачи.
В конструктор класса передаются следующие аргументы:
+ Политика запуска. Определяет, как задача будет выполняться:
  - =std::launch::async= — гарантирует, что задача будет выполнена асинхронно в отдельном потоке;
  - =std::launch::deferred= — задача будет выполнена «лениво» (когда будет запрошен результат).
+ Вызываемая функция.
+ Передаваемые в функцию аргументы.

Стандарт гарантирует, что окончание выполнения потока, запущенного вызовом =std::async=, синхронизировано с вызовом получения результата объектом =std::future= или освобождением общего состояния — области памяти, ответственной за передачу результата.
Класс =std::future= представляет собой обертку, над каким-либо значением или объектом, вычисление или получение которого происходит отложено. Точнее, =future= предоставляет доступ к некоторому разделяемому состоянию, которое состоит из 2-х частей: данные(здесь лежит значение) и флаг готовности.

#+begin_src cpp
auto func(int x, std::string str) { ... }

auto future = std::async(std::launch::async, func, 42, "Hello");
future.get();
#+end_src

* Атомарные операции
** std::atomic
Атомарный объект – это такой объект операции над которым можно считать неделимыми, т.е. такими, которые не могут быть прерваны или результат которых не может быть получен, до окончания операции. В C++ в шаблонный класс =std::atomic<>= можно обертывать и многие другие типы, что способствует атомарным операциям над соответствующим типом.
В С++20 появился класс =std::atomic_ref=, которые позволяет выполнять отомарные операции над значением по ссылке.
[[./atomic/main.cpp][Пример]]

** atomic operations

* Синхронизация выполнения
** mutual exclusion
** condition variables
** semaphores
** latches and barriers
=std::latch= — это примитив синхронизации,  который позволяет одному или нескольким потокам ожидать, пока другие потоки не завершат выполнение. В отличие от =std::barrier=, он не перезагружается после достижения условия синхронизации, что делает его полезным для одноразовой координации.
=std::latch= полезен в ситуациях, когда необходимо, чтобы один поток ждал завершения других потоков.

#+begin_src cpp
    std::latch work_done{std::size(jobs)};

    auto work = [&](Job& my_job)
    {
        ...
        work_done.count_down();
        work_done.wait();
        ...
    };

    for (auto& job : jobs)
    {
        job.action = std::thread{work, std::ref(job)};
    }
#+end_src

=std::barrier= — это примитив синхронизации, добавленный в C++20, который позволяет координировать выполнение группы потоков. Каждый поток выполняет свою работу до определенной точки (барьера) и ждет, пока все остальные потоки достигнут этой же точки, после чего выполнение продолжается.
=std::barrier= полезен в параллельных вычислениях, где важно, чтобы все потоки завершили определенную задачу перед переходом к следующей.

#+begin_src cpp
    auto on_completion = []() noexcept
    {
        ...
    };

    std::barrier sync_point(std::ssize(workers), on_completion);

    auto work = [&](std::string name)
    {
        ...
        sync_point.arrive_and_wait();
        ...
        sync_point.arrive_and_wait();
    };

    for (auto const& worker : workers)
    {
        threads.emplace_back(work, worker);
    }
#+end_src


** каналы

* Ошибки при работе с многопоточностью
** Взаимоблокировки (мертвые замки)
Ситуация, когда два потока блокируют друг друга, ожидая освобождения ресурсов, что приводит к «заморозке» программы.

** Гонки данных (рассовые условия)
Возникает, когда два или более потока пытаются одновременно изменить общие данные, что может привести к непредсказуемым результатам.

** Тупик
Возникает, когда два или более потока пытаются завладеть двумя или более ресурсами, проявляющаяся бесконечным взаимным ожиданием.

** Ожидание на блокировках (Thread starvation)
Основное время потока проводится не в исполнении полезной работы, а в ожидании блокированного другим потоком ресурса.
