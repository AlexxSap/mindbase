#+title: Redis

* Установка и запуск из docker
#+begin_src shell
# установка из образа
docker pull redis

# запуск
docker run --name some-redis -p 6379:6379 -d redis

# запуск контейнера
docker start -a some-redis

# подключение к командной строке redis
docker network create some-network
docker run -it --network some-network --rm redis redis-cli -h some-redis
#+end_src

* Что такое Redis
=Redis= — это in-memory noSQL СУБД с открытым исходным кодом класса key-value.
Может применяться для решения самых разных задач:
+ =Кэширование= — самая частая задача, которую решают при помощи этой СУБД.
+ =Распределенная блокировка= (distributed lock). Применяется, если нужно разграничить доступ из нескольких распределенных сервисов к общему изменяемому ресурсу.
+ =Управление сессиями=. Redis можно использовать как централизованное хранилище сессий. С его помощью можно задавать время жизни сессии и вообще очень гибко управлять другими метаданными в рамках сессии.
+ =Ограничение нагрузки на определенный сервис= (Rate Limiter). Чаще всего речь идет о количестве API-вызовов в единицу времени.

=Redis= — это большая распределенная hash-таблица, где в качестве ключа используется произвольная строка, а в качестве значения — одна из поддерживаемых структур данных (строки, списки, хеш-таблицы, set, отсортированные set и т.д.).

При работе с =Redis= важно не забывать про ещё одно его отличительное свойство: он ~однопоточный~. Это значит, что все операции чтения и записи данных происходят строго синхронно в одном потоке выполнения. Естественно, для удержания большого количества сетевых соединений и облегчения нагрузки на IO используются вспомогательные потоки. Но поток чтения/запиcи остаётся основным узким местом.

Характеристики:
+ =Персистентность=: есть два режима хранения — RDB (Redis database - периодически сохраняет снэпшот всего dataset. Для этого выполняется fork основного процесса и запускается процедура записи снэпшота — BGSAVE) и AOF (append only file - реализует журнал операций, где все новые операции просто дописываются в конец файла).
+ =Поддержка отказоустойчивости= в различных топологиях на все случаи жизни и под любые задачи.
+ =Информационная безопасность=: контроль доступа и шифрование данных.
+ =Configuration management= и мониторинг.

Redis поддерживает различные топологии развёртывания:
+ =Один узел= или stand-alone. Самая простая топология. Имеет право на существование, но исключительно для сред разработки и тестирования, поскольку не является отказоустойчивой.
+ =Master-Replica= (Secondary). В такой топологии между мастером и репликой происходит постоянная асинхронная репликация. Для принудительной синхронизации, то есть для перехода на синхронный режим, в Redis есть специальная команда WAIT.
+ =Sentinel=. Эта топология развёртывания широко применялась на ранних версиях Redis, до поддержки полноценного кластера. Она состоит из отдельных специальных узлов, которые мониторят работу основных узлов Redis, отслеживают сбои Master и запускают процесс восстановления. Работает поверх топологии Master-Replica.
+ =Полноценный кластер=, который состоит из набора мастер-узлов и набора реплик (secondary-узлы). Для репликации используется протокол Gossip: распространение информации в нем идет способом, похожим на эпидемию — каждый узел передает информацию известным ему «соседям». Клиенты могут работать как с мастером, так и с репликой, но с реплики идет только чтение.

* Ключи
=Redis= — хранилище данных в формате «ключ-значение».
Факты о ключах:
- Ключи в Redis — бинарно-безопасные (binary safe) строки.
- Слишком длинные ключи — плохая идея, не только из-за занимаемой памяти, но так же и в связи с увеличением времени поиска определенного ключа в множестве в связи с дорогостоящим сравнением.
- Хорошая идея — придерживаться схемы при построении ключей: «object-type:id:field».

* Типы данных
- =Строки= (strings). Базовый тип данных Redis. Строки в Redis бинарно-безопасны, могут использоваться так же как числа, ограничены размером 512 Мб.
- =Списки= (lists). Классические списки строк, упорядоченные в порядке вставки, которая возможна как со стороны головы, так и со стороны хвоста списка. Максимальное количество элементов — 2^32 — 1.
- =Множества= (sets). Множества строк в математическом понимании: не упорядочены, поддерживают операции вставки, проверки вхождения элемента, пересечения и разницы множеств. Максимальное количество элементов — 2^32 — 1.
- =Хеш-таблицы= (hashes). Классические хеш-таблицы или ассоциативные массивы. Максимальное количество пар «ключ-значение» — 2^32 — 1.
- =Упорядоченные множества= (sorted sets). Упорядоченное множество отличается от обычного тем, что его элементы упорядочены по особому параметру «score». ZSet — упорядоченное множество. Идеально для выбора данных по временному диапазону, например, метрики. Но можно использовать и как очередь с приоритетом, например, для уведомлений или событий. И что еще важно: ZSet реализован не через дерево, как можно было бы подумать, а через хэшмап с дополнительным скип-индексом.

* Основные команды
1. SET key value [EX seconds] - Сохраняет строковое значение по ключу. Можно задать таймаут: время через которое ключ автоматически удалится из базы.
#+begin_src go
result, err := c.Set(ctx, key, value, ttl).Result()
#+end_src

2. GET key - GET key достаёт строковое значение по ключу.
#+begin_src go
result, err := c.Get(ctx, key).Result()
#+end_src

3. SADD key member - Добавляет значение в множество, хранящееся по ключу. Если такого множества ещё нет — создаёт. Но SADD key member не позволяет задать таймаут: значения из множеств надо удалять самому.
#+begin_src go
result, err := c.SAdd(ctx, key, member).Result()
#+end_src

4. SREM key member [member...] - Удаляет значение из множества, хранящегося по ключу. Если это было последнее значение — сам ключ тоже будет удалён.
#+begin_src go
result, err := c.SRem(ctx, key, members).Result()
#+end_src

5. ZADD key member - ZADD и ZREM работают аналогично SADD и SREM, но с упорядоченными множествами.
#+begin_src go
result, err := c.ZAdd(ctx, key, member).Result()
#+end_src

6. ZRANGE key start stop [BYSCORE | BYLEX] [REV] [LIMIT offset count] - Быстро выбирает из упорядоченного множества значения в заданном диапазоне. Можно дополнительно задать количество и сдвиг значений, чтобы реализовать, например, пагинацию.
#+begin_src go
result, err := c.ZRangeByScore(ctx, key, &redis.ZRangeBy{
  Min: strconv.FormatInt(from, 10),
  Max: strconv.FormatInt(to, 10),
  Count: int64(limitCount),
  Offset: int64(limitOffset),
}).Result()
#+end_src

* Простой пример
Сначала нужно установить коннектор и запустить redis
#+begin_src shell
go get github.com/redis/go-redis/v9
docker run --name redis-test-instance -p 6379:6379 -d redis
#+end_src

Потом создаём проект
#+begin_src go
package main

import (
	"context"
	"fmt"

	"github.com/redis/go-redis/v9"
)

func main() {
	fmt.Println("hello redis world")

	client := redis.NewClient(&redis.Options{
		Addr:     "localhost:6379",
		Password: "",
		DB:       0,
	})

	ctx := context.Background()
	status, err := client.Ping(ctx).Result()
    if err != nil {
        log.Fatalln("Redis connection was refused")
    }
    fmt.Println(status)

	err := client.Set(ctx, "some", "value", 0).Err()
	if err != nil {
		panic(err)
	}

	val, err := client.Get(ctx, "some").Result()
	if err != nil {
		panic(err)
	}
	fmt.Println(val)
}
#+end_src

* Пример работы со структурами
#+begin_src go
type Person struct {
    Name string `redis:"name"`
    Age  int    `redis:"age"`
}
...
client.HSet(ctx, "STRUCT", Person{"John Doe", 15})
...
var person Person
err = rdb.HGetAll(ctx, "STRUCT").Scan(&person)
if err != nil {
	fmt.Println("Key STRUCT not found in Redis cache")
} else {
	fmt.Printf("STRUCT has value %+v\n", person)
}
#+end_src

* Pipelines
Позволяет выполнить несколько команд в одной операции
#+begin_src go
pipe := rdb.Pipeline()

incr := pipe.Incr(ctx, "pipeline_counter")
pipe.Expire(ctx, "pipeline_counter", time.Hour)

cmds, err := pipe.Exec(ctx)
if err != nil {
	panic(err)
}

// The value is available only after Exec is called.
fmt.Println(incr.Val())
#+end_src

или можно использовать замыкание. В cmds содержится результат выполненных операций.
#+begin_src go
var incr *redis.IntCmd

cmds, err := rdb.Pipelined(ctx, func(pipe redis.Pipeliner) error {
	incr = pipe.Incr(ctx, "pipelined_counter")
	pipe.Expire(ctx, "pipelined_counter", time.Hour)
	return nil
})
if err != nil {
	panic(err)
}

for _, cmd := range cmds {
    fmt.Println(cmd.(*redis.StringCmd).Val())
}

// The value is available only after the pipeline is executed.
fmt.Println(incr.Val())
#+end_src

* Транзакции
Используя транзакции, вы можете отслеживать изменения в ключах и выполнять конвейер только в том случае, если отслеживаемые ключи не были изменены другим клиентом. Такой метод разрешения конфликтов также известен как оптимистическая блокировка.
#+begin_src
WATCH mykey

val = GET mykey
val = val + 1

MULTI
SET mykey $val
EXEC
#+end_src

Можно использовать транзакционные конвейеры с Watch.
#+begin_src go
// Redis transactions use optimistic locking.
const maxRetries = 1000

// Increment transactionally increments the key using GET and SET commands.
func increment(key string) error {
	// Transactional function.
	txf := func(tx *redis.Tx) error {
		// Get the current value or zero.
		n, err := tx.Get(ctx, key).Int()
		if err != nil && err != redis.Nil {
			return err
		}

		// Actual operation (local in optimistic lock).
		n++

		// Operation is commited only if the watched keys remain unchanged.
		_, err = tx.TxPipelined(ctx, func(pipe redis.Pipeliner) error {
			pipe.Set(ctx, key, n, 0)
			return nil
		})
		return err
	}

    // Retry if the key has been changed.
	for i := 0; i < maxRetries; i++ {
		err := rdb.Watch(ctx, txf, key)
		if err == nil {
			// Success.
			return nil
		}
		if err == redis.TxFailedErr {
			// Optimistic lock lost. Retry.
			continue
		}
		// Return any other error.
		return err
	}

	return errors.New("increment reached maximum number of retries")
}
#+end_src

* Transaction pipelines
Позволяет клиенту Redis отправлять несколько запросов на сервер, не дожидаясь ответов и читая их все сразу.
#+begin_src go
pipe := db.Client.TxPipeline()
pipe.Set(Ctx, "language", "golang")
pipe.Set(Ctx, "year", 2009)
results, err := pipe.Exec()
#+end_src
